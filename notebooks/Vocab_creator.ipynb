{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gensim\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../notebooks/Functions/')\n",
    "from TextMiningProcesses import column_lemmatizer, column_stemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/Appliances.json\", lines = True)\n",
    "df = df.dropna(subset='reviewText')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "features = df['reviewText'].iloc[0:150000]\n",
    "target = df['overall'].iloc[0:150000]\n",
    "\n",
    "lemmed_features = column_stemmatizer(features)\n",
    "\n",
    "vectored_features = vectorizer.fit_transform(lemmed_features)\n",
    "\n",
    "# Make a dataframe for machine learning\n",
    "# total_features = pd.DataFrame(vectored_features.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# print(total_features.shape)\n",
    "# print(target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_header_list = vectorizer.get_feature_names_out()\n",
    "\n",
    "Q1_header_string = ','.join(map(str, Q1_header_list))\n",
    "\n",
    "with open('../notebooks/Q1_full_vocab_list.csv', 'w') as file:\n",
    "    file.write(Q1_header_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_rf_model = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, n_jobs=-1)\n",
    "\n",
    "# rfecv = RFE(estimator=best_rf_model, step=1000, n_features_to_select=3000, verbose=2)\n",
    "\n",
    "# rfecv.fit(total_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfecv.score(total_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features01 = rfecv.support_\n",
    "# best_features01_df = total_features.loc[:, features01]\n",
    "# best_features01 = best_features01_df.columns.tolist()\n",
    "# print(len(best_features01))\n",
    "# print(type(best_features01))\n",
    "# print(best_features01[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# with open('Q1_best_features.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(best_features01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/Appliances.json\", lines = True)\n",
    "df = df.dropna(subset='reviewText')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "features02 = df['reviewText'].iloc[150000:300000]\n",
    "target02 = df['overall'].iloc[150000:300000]\n",
    "\n",
    "lemmed_features02 = column_stemmatizer(features02)\n",
    "\n",
    "vectored_features02 = vectorizer.fit_transform(lemmed_features02)\n",
    "\n",
    "# Make a dataframe for machine learning\n",
    "# total_features02 = pd.DataFrame(vectored_features02.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# print(total_features02.shape)\n",
    "# print(target02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2_header_list = vectorizer.get_feature_names_out()\n",
    "\n",
    "Q2_header_string = ','.join(map(str, Q2_header_list))\n",
    "\n",
    "with open('../notebooks/Q2_full_vocab_list.csv', 'w') as file:\n",
    "    file.write(Q2_header_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_rf_model = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, n_jobs=-1)\n",
    "\n",
    "# rfe02 = RFE(estimator=best_rf_model, step=1000, n_features_to_select=3000, verbose=2)\n",
    "\n",
    "# rfe02.fit(total_features02, target02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features02 = rfe02.support_\n",
    "# best_features02_df = total_features02.loc[:, features02]\n",
    "# best_features02 = best_features02_df.columns.tolist()\n",
    "# print(len(best_features02))\n",
    "# print(type(best_features02))\n",
    "# print(best_features02[:8])\n",
    "\n",
    "# with open('Q2_best_features.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(best_features02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/Appliances.json\", lines = True)\n",
    "df = df.dropna(subset='reviewText')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "features03 = df['reviewText'].iloc[300000:450000]\n",
    "target03 = df['overall'].iloc[300000:450000]\n",
    "\n",
    "lemmed_features03 = column_stemmatizer(features03)\n",
    "\n",
    "vectored_features03 = vectorizer.fit_transform(lemmed_features03)\n",
    "\n",
    "# Make a dataframe for machine learning\n",
    "# total_features03 = pd.DataFrame(vectored_features03.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# print(total_features03.shape)\n",
    "# print(target03.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3_header_list = vectorizer.get_feature_names_out()\n",
    "\n",
    "Q3_header_string = ','.join(map(str, Q3_header_list))\n",
    "\n",
    "with open('../notebooks/Q3_full_vocab_list.csv', 'w') as file:\n",
    "    file.write(Q3_header_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_rf_model = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, n_jobs=-1)\n",
    "\n",
    "# rfe03 = RFE(estimator=best_rf_model, step=1000, n_features_to_select=3000, verbose=2)\n",
    "\n",
    "# rfe03.fit(total_features03, target03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features03 = rfe03.support_\n",
    "# best_features03_df = total_features03.loc[:, features03]\n",
    "# best_features03 = best_features03_df.columns.tolist()\n",
    "# print(len(best_features03))\n",
    "# print(type(best_features03))\n",
    "# print(best_features03[:8])\n",
    "\n",
    "# with open('Q3_best_features.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(best_features03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/Appliances.json\", lines = True)\n",
    "df = df.dropna(subset='reviewText')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "features04 = df['reviewText'].iloc[450000:]\n",
    "target04 = df['overall'].iloc[450000:]\n",
    "\n",
    "lemmed_features04 = column_stemmatizer(features04)\n",
    "\n",
    "vectored_features04 = vectorizer.fit_transform(lemmed_features04)\n",
    "\n",
    "# Make a dataframe for machine learning\n",
    "# total_features04 = pd.DataFrame(vectored_features04.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# print(total_features04.shape)\n",
    "# print(target04.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4_header_list = vectorizer.get_feature_names_out()\n",
    "\n",
    "Q4_header_string = ','.join(map(str, Q4_header_list))\n",
    "\n",
    "with open('../notebooks/Q4_full_vocab_list.csv', 'w') as file:\n",
    "    file.write(Q4_header_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13756\n",
      "13053\n",
      "12280\n",
      "14256\n",
      "53345\n",
      "19370\n"
     ]
    }
   ],
   "source": [
    "# with open('../notebooks/Q1_full_vocab_list.csv', 'r') as file:\n",
    "#     csv_list = file.read().strip()\n",
    "#     header_list01 = csv_list.split(',')\n",
    "\n",
    "# with open('../notebooks/Q2_full_vocab_list.csv', 'r') as file:\n",
    "#     csv_list = file.read().strip()\n",
    "#     header_list02 = csv_list.split(',')\n",
    "\n",
    "# with open('../notebooks/Q3_full_vocab_list.csv', 'r') as file:\n",
    "#     csv_list = file.read().strip()\n",
    "#     header_list03 = csv_list.split(',')\n",
    "\n",
    "# with open('../notebooks/Q4_full_vocab_list.csv', 'r') as file:\n",
    "#     csv_list = file.read().strip()\n",
    "#     header_list04 = csv_list.split(',')\n",
    "\n",
    "header_list = []\n",
    "header_list.extend(Q1_header_list)\n",
    "header_list.extend(Q2_header_list)\n",
    "header_list.extend(Q3_header_list)\n",
    "header_list.extend(Q4_header_list)\n",
    "\n",
    "print(len(Q1_header_list))\n",
    "print(len(Q2_header_list))\n",
    "print(len(Q3_header_list))\n",
    "print(len(Q4_header_list))\n",
    "print(len(header_list))\n",
    "\n",
    "unique_header_list = list(set(header_list))\n",
    "\n",
    "print(len(unique_header_list))\n",
    "\n",
    "header_string = ','.join(map(str, unique_header_list))\n",
    "\n",
    "with open('../notebooks/full_vocab_list_stemmed.csv', 'w') as file:\n",
    "    file.write(header_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_rf_model = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, n_jobs=-1)\n",
    "\n",
    "# rfe04 = RFE(estimator=best_rf_model, step=1000, n_features_to_select=3000, verbose=2)\n",
    "\n",
    "# rfe04.fit(total_features04, target04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features04 = rfe04.support_\n",
    "# best_features04_df = total_features04.loc[:, features04]\n",
    "# best_features04 = best_features04_df.columns.tolist()\n",
    "# print(len(best_features04))\n",
    "# print(type(best_features04))\n",
    "# print(best_features04[:8])\n",
    "\n",
    "# with open('Q4_best_features.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(best_features04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import csv\n",
    "\n",
    "# import sys\n",
    "\n",
    "# sys.path.append('../notebooks/Functions/')\n",
    "# from NewTextMiningProcesses import new_column_lemmatizer, new_column_stemmatizer, new_count_vectorize_data\n",
    "\n",
    "# df = pd.read_json(\"../data/Appliances.json\", lines = True)\n",
    "# df = df.dropna(subset='reviewText')\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "# all_features = df['reviewText']\n",
    "# all_target = df['overall']\n",
    "\n",
    "# lemmed_best_features = new_column_lemmatizer(all_features)\n",
    "\n",
    "# vectored_best_features = vectorizer.fit_transform(lemmed_best_features)\n",
    "\n",
    "# # Make a dataframe for machine learning\n",
    "# total_best_features = pd.DataFrame(vectored_best_features.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# print(total_best_features.shape)\n",
    "# print(all_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lem_stem_4000_best_features = pd.concat([total_best_features, all_target], axis = 1)\n",
    "\n",
    "# print(lem_stem_4000_best_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lem_stem_4000_best_features.to_csv('../data/lem_stem_4000_best_features.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del lemmed_best_features\n",
    "# del vectored_best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# best_rf_model = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, n_jobs=-1)\n",
    "\n",
    "# best_rfecv = RFECV(estimator=best_rf_model, step=1000, cv=StratifiedKFold(2), verbose=2)\n",
    "\n",
    "# best_rfecv.fit(total_best_features, all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_best_features = best_rfecv.support_\n",
    "# best_best_features_df = total_best_features.loc[:, best_best_features]\n",
    "# best_best_features_list = best_best_features_df.columns.tolist()\n",
    "# print(len(best_best_features_list))\n",
    "# print(type(best_best_features_list))\n",
    "# print(best_best_features_list[:8])\n",
    "\n",
    "# with open('best_best_features.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(best_best_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_best_features_list == list(total_best_features.columns))\n",
    "\n",
    "# best_rfecv.score(total_best_features, all_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
