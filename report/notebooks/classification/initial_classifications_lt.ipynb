{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Summary\n",
    "\n",
    "The target data is displayed and the imbalance is acknowledged.\n",
    "\n",
    "Feature Data is pre processed 4 ways to cover all combinations of lemmatization, stemmatization, CountVectorization\n",
    "and RFID Vectorization.\n",
    "\n",
    "An initial LinearRegression model shows correlation between all preprocessed data and the target data, but this correlation\n",
    "is not supported by the RSquared value.\n",
    "\n",
    "All data is resampled using RandomUndersampler and all correlation is lost.\n",
    "\n",
    "Document concludes that further investigation should follow regularization, non linear regression modelling and consider \n",
    "classification\n",
    "\n",
    "\n",
    "# Initial Regression Modelling\n",
    "\n",
    "## Uncut data Linear regression Parameters\n",
    "\n",
    "These values were taken from the values of the LinearRegression before the values were cut into rounded integer values, the errors here, especially the R Squared, show the amount of error produced by the values as floats. It should also be noted that in the cut process we started with min/max edges at -10/10, but there were a large number of NaN values produced which prevented the classification report from running, so these were modified to include the min max values of the series. A large amount of error could be contained there. The equations that generated these numbers have now been removed from the notebook.\n",
    "\n",
    "| Tokenization | Vectorization | Coefficient | R Squared |\n",
    "|----------|----------|----------|----------|\n",
    "| Lemmatized | Count Vectorized | 0.816 | -6.49 |\n",
    "| Lemmatized | TFIDF Vectorized | 0.849 | -1.40 |\n",
    "| Stemmatized | Count Vectorized | 0.744 | -.98 |\n",
    "| Stemmatized | TFIDF Vectorized | 0.793 | -0.35 |\n",
    "\n",
    "Across the board it can be seen that the RSquared values are not supporting the detected regression lines.\n",
    "\n",
    "## Linear Regression Parameters after cutting\n",
    "\n",
    "| Data Type | Train/Test | Coefficient | R Squared | P Value | Precision | Recall | F1 | Geometric Mean |\n",
    "|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
    "| Lemmatized Count Vectorized | Train | 1.041 | 0.906 | 0.0 | 0.70 | 0.68 | 0.66 | 0.76 |\n",
    "| Lemmatized Count Vectorized | Test | 0.550 | 0.484 | 0.0 | 0.33 | 0.37 | 0.33 | 0.50 |\n",
    "| Lemmatized TFIDF Vectorized | Train | 1.031 | 0.921 | 0.0 | 0.71 | 0.71 | 0.69 | 0.78 |\n",
    "| Lemmatized TFIDF Vectorized | Test | 0.641 | 0.549 | 0.0 | 0.35 | 0.39 | 0.35 | 0.51 |\n",
    "| Stemmatized Count Vectorized | Train | 1.053 | 0.867 | 0.0 | 0.62 | 0.59 | 0.55 | 0.69 |\n",
    "| Stemmatized Count Vectorized | Test | 0.670 | 0.544 | 0.0 | 0.34 | 0.35 | 0.31 | 0.49 |\n",
    "| Stemmatized TFIDF Vectorized | Train | 1.035 | 0.890 | 0.0 | 0.67 | 0.64 | 0.60 | 0.72 |\n",
    "| Stemmatized TFIDF Vectorized | Test | 0.755 | 0.612 | 0.0 | 0.37 | 0.39 | 0.34 | 0.52 |\n",
    "\n",
    "Cutting the data has significantly improved the R Squared scores at the cost of the coefficient.  \n",
    "The highest scoring data is the Stemmatized TFIDF Vectorized data with the highest coefficient and R Squared value across both training and test data. It scores similar to the other datasets in terms of recall, precision and f1 score and has the highest test Geometric mean by a narrow margin.\n",
    "\n",
    "### Stemmatized TFIDF Vectorized Test Data Confusion Matrix\n",
    "\n",
    "| Predicted Values | 1 | 2 | 3 | 4 | 5 |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| **Real Values** |  |  |  |  |  |\n",
    "| **1**| 1680 | 244 | 149 | 103 | 262 |\n",
    "| **2**| 1519 | 370 | 279 | 223 | 417 |\n",
    "| **3**| 1004 | 381 | 508 | 622 | 1274 |\n",
    "| **4**| 383 | 182 | 358 | 884 | 2615 |\n",
    "| **5**| 188 | 99 | 183 | 748 | 3772 |\n",
    "\n",
    "\n",
    "## Linear Regression Parameters after Under Sampling and cutting\n",
    "\n",
    "| Data Type | Train/Test | Coefficient | R Squared | P Value | Precision | Recall | F1 | Geometric Mean |\n",
    "|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
    "| Lemmatized Count Vectorized | Train | 0.360 | 0.357 | 0.0 | 0.63 | 0.60 | 0.61 | 0.70 |\n",
    "| Lemmatized Count Vectorized | Test | 0.139 | 0.150 | 2.2 | 0.39 | 0.36 | 0.37 | 0.48 |\n",
    "| Lemmatized TFIDF Vectorized | Train | 0.377 | 0.367 | 0.0 | 0.63 | 0.59 | 0.59 | 0.69 |\n",
    "| Lemmatized TFIDF Vectorized | Test | 0.148 | 0.157 | 1.2 | 0.36 | 0.35 | 0.35 | 0.47 |\n",
    "| Stemmatized Count Vectorized | Train | 0.572 | 0.500 | 0.0 | 0.58 | 0.52 | 0.51 | 0.64 |\n",
    "| Stemmatized Count Vectorized | Test | 0.350 | 0.327 | 0.0 | 0.31 | 0.33 | 0.31 | 0.47 |\n",
    "| Stemmatized TFIDF Vectorized | Train | 0.643 | 0.550 | 0.0 | 0.59 | 0.52 | 0.50 | 0.64 |\n",
    "| Stemmatized TFIDF Vectorized | Test | 0.429 | 0.385 | 0.0 | 0.31 | 0.34 | 0.31 | 0.48 |\n",
    "\n",
    "Sampling with the RandomUnderSampler has had a surprisingly bad effect on the datasets. All scores have been lowered, which is a great surprise. Looking at the graph below a clear imbalance is visible with ratings 1 and 5 have the lions share of the data, so it would be expected that the resampling would improve the scores. (5 has 45.2% of the rows, 1 has 26.7%)\n",
    "\n",
    "![Graph showing target data 'overall' Distribution](../amazon_review/images/RatingDistribution.png)\n",
    "\n",
    "### Resampled Stemmatized TFIDF Vectorized Test Data Confusion Matrix\n",
    "\n",
    "| Predicted Values | 1 | 2 | 3 | 4 | 5 |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| **Real Values** |  |  |  |  |  |\n",
    "| **1**| 1940 | 374 | 331 | 410 | 1067 |\n",
    "| **2**| 1083 | 256 | 267 | 294 | 767 |\n",
    "| **3**| 795 | 274 | 370 | 512 | 1425 |\n",
    "| **4**| 421 | 165 | 238 | 561 | 1880 |\n",
    "| **5**| 535 | 207 | 271 | 803 | 3201 |\n",
    "\n",
    "This indicates that the Linear Regression model is not the best fit for the data in its current state. There are options at this point. Regularisation is a good option to elimnate some of the data causing noise in the predcitions. More complex regression models can also be employed to better fit the  data. Both have the risk of overfitting the data This risk will be further assessed later in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../data_cleaning/lem_stem_functions')\n",
    "\n",
    "from text_functions_init_ac import column_lemmatizer, column_stemmatizer, count_vectorize_data, tfidf_vectorize_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "# from imblearn.metrics import classification_report_imbalanced\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from matplotlib import pyplot as pyplot\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43043 entries, 0 to 43042\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   vote            43043 non-null  int64 \n",
      " 1   verified        43043 non-null  bool  \n",
      " 2   reviewTime      43043 non-null  object\n",
      " 3   reviewerID      43043 non-null  object\n",
      " 4   asin            43043 non-null  object\n",
      " 5   reviewerName    43043 non-null  object\n",
      " 6   reviewText      43043 non-null  object\n",
      " 7   summary         43043 non-null  object\n",
      " 8   unixReviewTime  43043 non-null  int64 \n",
      " 9   reviewYear      43043 non-null  int64 \n",
      " 10  reviewMonth     43043 non-null  int64 \n",
      " 11  reviewDay       43043 non-null  int64 \n",
      " 12  category        43043 non-null  object\n",
      " 13  description     43043 non-null  object\n",
      " 14  title           43043 non-null  object\n",
      " 15  brand           42533 non-null  object\n",
      " 16  feature         43043 non-null  object\n",
      " 17  rank            43043 non-null  object\n",
      " 18  main_cat        43034 non-null  object\n",
      " 19  price           24890 non-null  object\n",
      "dtypes: bool(1), int64(5), object(14)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../../../data/processed/train.csv')\n",
    "test = pd.read_csv('../../../data/processed/test.csv')\n",
    "\n",
    "X_train = train.drop(columns='overall')\n",
    "y_train = train['overall']\n",
    "X_test = test.drop(columns='overall')\n",
    "y_test = test['overall']\n",
    "\n",
    "\n",
    "# Identify the column to be processed\n",
    "X_train.info() # reviewText is the column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.452013\n",
       "1    0.267035\n",
       "4    0.134377\n",
       "3    0.077411\n",
       "2    0.069163\n",
       "Name: overall, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_train.info()\n",
    "\n",
    "normalized_counts = y_train.value_counts(normalize=True)\n",
    "\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "sns.barplot(x=normalized_counts.index, y = normalized_counts.values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is not very well balanced and may wish to consider over or undersampling the data. from the size of the data it may be best to undersample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "With two methods of tokenizing ands 2 methods of vectorizing the text fields, that gives us 4 potential cobinations to test the regression.\n",
    "To test the regression we can use the LinearRegression model to check for a linear regression and we can use the crossvalidation to verify\n",
    "any detected linear relationships.\n",
    "\n",
    "First though we must identify and preprocess our 4 types of data\n",
    "\n",
    "This cell could take a few minutes to run.\n",
    "\"\"\"\n",
    "\n",
    "# Lemmatized data\n",
    "X_lem_train = column_lemmatizer(X_train['reviewText'])\n",
    "X_lem_test = column_lemmatizer(X_test['reviewText'])\n",
    "\n",
    "# Stemmatized data\n",
    "X_stem_train = column_stemmatizer(X_train['reviewText'])\n",
    "X_stem_test = column_stemmatizer(X_test['reviewText'])\n",
    "\n",
    "# Lemmatized CountVectorized data\n",
    "X_lem_CV_train, X_lem_CV_test = count_vectorize_data(X_lem_train, X_lem_test)\n",
    "\n",
    "# Lemmatized TFIDFVectorized data\n",
    "X_lem_RFID_train, X_lem_RFID_test = tfidf_vectorize_data(X_lem_train, X_lem_test)\n",
    "\n",
    "# Stemmatized CountVectorized data\n",
    "X_stem_CV_train, X_stem_CV_test = count_vectorize_data(X_stem_train, X_stem_test)\n",
    "\n",
    "# Stemmatized TFIDFVectorized data\n",
    "X_stem_RFID_train, X_stem_RFID_test = tfidf_vectorize_data(X_stem_train, X_stem_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report (lem_cv):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.76      0.72      4774\n",
      "           2       0.21      0.14      0.17      1276\n",
      "           3       0.26      0.18      0.21      1477\n",
      "           4       0.38      0.26      0.31      2580\n",
      "           5       0.73      0.84      0.78      8340\n",
      "\n",
      "    accuracy                           0.64     18447\n",
      "   macro avg       0.45      0.44      0.44     18447\n",
      "weighted avg       0.60      0.64      0.61     18447\n",
      "\n",
      "Confusion Matrix (lem_cv):\n",
      " [[3630  319  220  115  490]\n",
      " [ 595  182  144  115  240]\n",
      " [ 407  123  267  253  427]\n",
      " [ 224   99  207  678 1372]\n",
      " [ 430  133  197  615 6965]]\n",
      "Accuracy Score (lem_cv): 0.6354420773025424\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model_lem_cv = LogisticRegression(max_iter=1000)\n",
    "logistic_model_lem_cv.fit(X_lem_CV_train, y_train)\n",
    "y_pred_logistic_lem_cv = logistic_model_lem_cv.predict(X_lem_CV_test)\n",
    "logistic_report_lem_cv = classification_report(y_test, y_pred_logistic_lem_cv)\n",
    "confusion_matrix_logistic_lem_cv = confusion_matrix(y_test, y_pred_logistic_lem_cv)\n",
    "accuracy_logistic_lem_cv = accuracy_score(y_test, y_pred_logistic_lem_cv)\n",
    "print(\"Logistic Regression Classification Report (lem_cv):\\n\", logistic_report_lem_cv)\n",
    "print(\"Confusion Matrix (lem_cv):\\n\", confusion_matrix_logistic_lem_cv)\n",
    "print(\"Accuracy Score (lem_cv):\", accuracy_logistic_lem_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report (lem_cv):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.36      0.35      4774\n",
      "           2       0.09      0.04      0.06      1276\n",
      "           3       0.14      0.08      0.10      1477\n",
      "           4       0.23      0.09      0.13      2580\n",
      "           5       0.52      0.68      0.59      8340\n",
      "\n",
      "    accuracy                           0.42     18447\n",
      "   macro avg       0.27      0.25      0.25     18447\n",
      "weighted avg       0.37      0.42      0.39     18447\n",
      "\n",
      "Confusion Matrix (lem_cv):\n",
      " [[1730  212  205   94 2533]\n",
      " [ 443   52   82   55  644]\n",
      " [ 420   70  114   79  794]\n",
      " [ 729   64  162  242 1383]\n",
      " [1667  171  251  564 5687]]\n",
      "Accuracy Score (lem_cv): 0.4241882148858893\n"
     ]
    }
   ],
   "source": [
    "# 2. Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC\n",
    "svm_model_lem_cv = SVC(max_iter=1000)\n",
    "svm_model_lem_cv.fit(X_lem_CV_train, y_train)\n",
    "y_pred_svm_lem_cv = svm_model_lem_cv.predict(X_lem_CV_test)\n",
    "svm_report_lem_cv = classification_report(y_test, y_pred_svm_lem_cv)\n",
    "confusion_matrix_svm_lem_cv = confusion_matrix(y_test, y_pred_svm_lem_cv)\n",
    "accuracy_svm_lem_cv = accuracy_score(y_test, y_pred_svm_lem_cv)\n",
    "print(\"SVM Classification Report (lem_cv):\\n\", svm_report_lem_cv)\n",
    "print(\"Confusion Matrix (lem_cv):\\n\", confusion_matrix_svm_lem_cv)\n",
    "print(\"Accuracy Score (lem_cv):\", accuracy_svm_lem_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report (lem_cv):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.61      0.55      4774\n",
      "           2       0.11      0.02      0.03      1276\n",
      "           3       0.14      0.04      0.06      1477\n",
      "           4       0.22      0.08      0.12      2580\n",
      "           5       0.58      0.76      0.66      8340\n",
      "\n",
      "    accuracy                           0.52     18447\n",
      "   macro avg       0.31      0.30      0.28     18447\n",
      "weighted avg       0.44      0.52      0.46     18447\n",
      "\n",
      "Confusion Matrix (lem_cv):\n",
      " [[2930   59  101  158 1526]\n",
      " [ 597   24   37   71  547]\n",
      " [ 535   25   60  101  756]\n",
      " [ 517   37   83  207 1736]\n",
      " [1365   74  135  400 6366]]\n",
      "Accuracy Score (lem_cv): 0.51970510110045\n"
     ]
    }
   ],
   "source": [
    "# 3. K-Nearest Neighbors (KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_lem_cv = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model_lem_cv.fit(X_lem_CV_train, y_train)\n",
    "y_pred_knn_lem_cv = knn_model_lem_cv.predict(X_lem_CV_test)\n",
    "knn_report_lem_cv = classification_report(y_test, y_pred_knn_lem_cv)\n",
    "confusion_matrix_knn_lem_cv = confusion_matrix(y_test, y_pred_knn_lem_cv)\n",
    "accuracy_knn_lem_cv = accuracy_score(y_test, y_pred_knn_lem_cv)\n",
    "print(\"KNN Classification Report (lem_cv):\\n\", knn_report_lem_cv)\n",
    "print(\"Confusion Matrix (lem_cv):\\n\", confusion_matrix_knn_lem_cv)\n",
    "print(\"Accuracy Score (lem_cv):\", accuracy_knn_lem_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report (lem_cv):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.78      0.73      4774\n",
      "           2       0.78      0.01      0.03      1276\n",
      "           3       0.76      0.02      0.04      1477\n",
      "           4       0.54      0.03      0.05      2580\n",
      "           5       0.62      0.95      0.75      8340\n",
      "\n",
      "    accuracy                           0.64     18447\n",
      "   macro avg       0.68      0.36      0.32     18447\n",
      "weighted avg       0.65      0.64      0.54     18447\n",
      "\n",
      "Confusion Matrix (lem_cv):\n",
      " [[3723    3    3    6 1039]\n",
      " [ 646   18    2    9  601]\n",
      " [ 478    1   28   28  942]\n",
      " [ 247    1    1   69 2262]\n",
      " [ 394    0    3   16 7927]]\n",
      "Accuracy Score (lem_cv): 0.6377730796335448\n"
     ]
    }
   ],
   "source": [
    "# 4. Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model_lem_cv = RandomForestClassifier(n_estimators=100)\n",
    "rf_model_lem_cv.fit(X_lem_CV_train, y_train)\n",
    "y_pred_rf_lem_cv = rf_model_lem_cv.predict(X_lem_CV_test)\n",
    "rf_report_lem_cv = classification_report(y_test, y_pred_rf_lem_cv)\n",
    "confusion_matrix_rf_lem_cv = confusion_matrix(y_test, y_pred_rf_lem_cv)\n",
    "accuracy_rf_lem_cv = accuracy_score(y_test, y_pred_rf_lem_cv)\n",
    "print(\"Random Forest Classification Report (lem_cv):\\n\", rf_report_lem_cv)\n",
    "print(\"Confusion Matrix (lem_cv):\\n\", confusion_matrix_rf_lem_cv)\n",
    "print(\"Accuracy Score (lem_cv):\", accuracy_rf_lem_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report (lem_cv):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.62      0.59      4774\n",
      "           2       0.14      0.11      0.12      1276\n",
      "           3       0.14      0.10      0.12      1477\n",
      "           4       0.24      0.23      0.24      2580\n",
      "           5       0.66      0.68      0.67      8340\n",
      "\n",
      "    accuracy                           0.52     18447\n",
      "   macro avg       0.35      0.35      0.35     18447\n",
      "weighted avg       0.50      0.52      0.51     18447\n",
      "\n",
      "Confusion Matrix (lem_cv):\n",
      " [[2942  340  278  330  884]\n",
      " [ 497  137  101  165  376]\n",
      " [ 462  122  155  267  471]\n",
      " [ 403  141  209  595 1232]\n",
      " [ 918  253  386 1097 5686]]\n",
      "Accuracy Score (lem_cv): 0.5158020274299344\n"
     ]
    }
   ],
   "source": [
    "# 5. Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model_lem_cv = DecisionTreeClassifier()\n",
    "tree_model_lem_cv.fit(X_lem_CV_train, y_train)\n",
    "y_pred_tree_lem_cv = tree_model_lem_cv.predict(X_lem_CV_test)\n",
    "tree_report_lem_cv = classification_report(y_test, y_pred_tree_lem_cv)\n",
    "confusion_matrix_tree_lem_cv = confusion_matrix(y_test, y_pred_tree_lem_cv)\n",
    "accuracy_tree_lem_cv = accuracy_score(y_test, y_pred_tree_lem_cv)\n",
    "print(\"Decision Tree Classification Report (lem_cv):\\n\", tree_report_lem_cv)\n",
    "print(\"Confusion Matrix (lem_cv):\\n\", confusion_matrix_tree_lem_cv)\n",
    "print(\"Accuracy Score (lem_cv):\", accuracy_tree_lem_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
